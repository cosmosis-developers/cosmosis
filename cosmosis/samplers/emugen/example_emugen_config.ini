# Example EmugenSampler Configuration
# This file demonstrates all available configuration options for the emugen sampler
# Copy and modify this template for your own analysis

[emugen]
# =============================================================================
# EMULATION TARGET SETTINGS
# =============================================================================

# Which data vector components to emulate (leave empty to emulate full data vector)
# Format: space-separated list of section.parameter names
# Example: "shear_cl.ell galaxy_cl.theory" to emulate specific components
# Empty means emulate the complete data vector from data_vector section
keys = 

# Parameters that stay fixed during emulation (computed once and reused)
# Useful for computationally cheap quantities that don't vary much
# Format: space-separated list of section.parameter names
# Example: "distances.z distances.d_m distances.h"
fixed_keys = 

# Error vectors for weighted training (advanced feature, usually leave empty)
# Only needed if you want to weight training by measurement uncertainties
error_keys = 

# =============================================================================
# TRAINING CONFIGURATION
# =============================================================================

# Number of training iterations/cycles
# Each iteration: train emulator → run MCMC → add new training data → repeat
# Recommended: 3-6 iterations for most problems
# More iterations = better emulator but longer runtime
iterations = 5

# Number of exact (slow) calculations for initial training dataset
# This is the most time-consuming step, but crucial for emulator quality
# Recommended: 500-2000 for testing, 5000-20000 for production runs
# Rule of thumb: ~100-500 times the number of parameters
initial_size = 1000

# Additional exact calculations added in each iteration after the first
# Should be smaller than initial_size (typically 20-50% of initial_size)
# These points are selected from MCMC chain to improve emulator in high-likelihood regions
resample_size = 500

# Remove training points with chi² above this threshold
# Prevents poor fits from confusing the emulator
# Start with large value (1e6), reduce for refined training (100-1000)
# Should be much larger than your expected best-fit chi²
chi2_cut_off = 1e6

# Neural network training batch size
# Automatically increases each iteration: batch_size * (iteration + 1)
# Larger = faster training but more memory usage
# Recommended: 16-128 depending on your dataset size and available memory
batch_size = 32

# Number of neural network training epochs per iteration
# More epochs = better training but longer runtime
# Recommended: 5-20 for most problems
# Monitor training loss to see if you need more
training_iterations = 10

# =============================================================================
# MCMC SAMPLING SETTINGS
# =============================================================================

# Number of MCMC walkers (must be < initial_size)
# Rule of thumb: 2-4 times the number of free parameters
# More walkers = better exploration but slower per iteration
emcee_walkers = 20

# Number of MCMC samples per walker per iteration
# Total samples per iteration = emcee_walkers × emcee_samples
# Recommended: 1000-10000 depending on parameter space complexity
emcee_samples = 5000

# Burn-in: fraction of samples to discard (if < 1) or absolute number (if ≥ 1)
# Recommended: 0.2-0.5 for fraction, or 500-2000 for absolute number
# Higher burn-in needed if chains start far from high-likelihood region
emcee_burn = 0.3

# Thinning: keep every Nth sample to reduce autocorrelation
# 1 = keep all samples, 2 = keep every other sample, etc.
# Usually 1 is fine unless you have strong autocorrelation
emcee_thin = 1

# =============================================================================
# TEMPERING SETTINGS (for improved exploration)
# =============================================================================

# Likelihood tempering factor for early iterations
# Flattens likelihood to improve exploration: L_tempered = L^tempering
# 1.0 = no tempering, smaller values = more flattening
# Recommended: 0.05-0.5 for difficult parameter spaces, 1.0 for simple ones
tempering = 0.05

# File containing custom tempering schedule (optional)
# Text file with one tempering value per line (one per iteration)
# Leave empty to use constant tempering value above
# Example file content: 0.1\n0.3\n0.7\n1.0\n1.0
tempering_file = 

# =============================================================================
# PIPELINE EMULATION SETTINGS
# =============================================================================

# Last module in pipeline to be emulated (optional)
# Leave empty to emulate up to the likelihood calculation
# Specify module name to emulate only part of the pipeline
# Must be consistent with your choice of 'keys' parameter
# Example: "pk_to_cl" to emulate up to power spectrum projection
last_emulated_module = 

# =============================================================================
# PRE-TRAINED EMULATOR LOADING
# =============================================================================

# Skip training and load a pre-trained emulator
# Set to true if you have already trained an emulator and want to reuse it
# Useful for parameter studies or different data cuts with same theory
trained_before = false

# Path to pre-trained emulator file (required if trained_before = true)
# Should point to a .pkl file saved from a previous emugen run
# Example: "output/previous_run/emumodel_5.pkl"
load_emu_filename = 

# =============================================================================
# OUTPUT AND SAVING SETTINGS
# =============================================================================

# What to save during training
# Options:
#   "" (empty) = save nothing (not recommended, no way to check emulator quality)
#   "model"    = save only final trained emulator (minimal disk usage)
#   "all"      = save everything: models, training data, diagnostics, plots
# Recommended: "all" for development/testing, "model" for production runs
save_outputs = all

# Directory where outputs are saved (required if save_outputs is not empty)
# Will be created if it doesn't exist
# Contains: trained models, training datasets, diagnostic plots, etc.
save_outputs_dir = output/emugen_results

# =============================================================================
# REPRODUCIBILITY
# =============================================================================

# Random seed for reproducible results
# Set to any integer for reproducible runs
# Set to 0 for random seed (different results each time)
# Useful for testing and debugging
seed = 12345

# =============================================================================
# USAGE EXAMPLES FOR DIFFERENT SCENARIOS
# =============================================================================

# QUICK TEST RUN (fast, low accuracy):
# iterations = 2
# initial_size = 100
# resample_size = 50
# emcee_samples = 1000
# save_outputs = model

# DEVELOPMENT RUN (moderate speed and accuracy):
# iterations = 4
# initial_size = 1000
# resample_size = 500
# emcee_samples = 5000
# save_outputs = all

# PRODUCTION RUN (slow, high accuracy):
# iterations = 6
# initial_size = 10000
# resample_size = 2000
# emcee_samples = 10000
# save_outputs = model

# REUSE TRAINED EMULATOR:
# trained_before = true
# load_emu_filename = output/previous_run/emumodel_5.pkl
# save_outputs = model

# =============================================================================
# TROUBLESHOOTING TIPS
# =============================================================================

# If you get memory errors:
# - Reduce initial_size and batch_size
# - Use fewer emcee_walkers

# If emulator accuracy is poor:
# - Increase initial_size and training_iterations
# - Check diagnostic plots in save_outputs_dir
# - Ensure chi2_cut_off is reasonable

# If MCMC chains don't converge:
# - Increase emcee_samples and emcee_burn
# - Try lower tempering value
# - Check parameter priors are reasonable

# If walkers get stuck:
# - Ensure emcee_walkers < initial_size
# - Try higher tempering value
# - Check initial parameter ranges
